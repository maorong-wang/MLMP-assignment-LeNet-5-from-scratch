{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here's the hardware used to train the model. Please note that the training might be slow due to the fact that this code is implemented w/o GPU acceleration.\n",
        "\n"
      ],
      "metadata": {
        "id": "yxOSQQnURfbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmFJV_gKRmw9",
        "outputId": "04aae017-98fb-47c7-8492-1b44ba90e689"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:                    x86_64\n",
            "CPU op-mode(s):                  32-bit, 64-bit\n",
            "Byte Order:                      Little Endian\n",
            "Address sizes:                   46 bits physical, 48 bits virtual\n",
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "Thread(s) per core:              2\n",
            "Core(s) per socket:              1\n",
            "Socket(s):                       1\n",
            "NUMA node(s):                    1\n",
            "Vendor ID:                       GenuineIntel\n",
            "CPU family:                      6\n",
            "Model:                           79\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:                        0\n",
            "CPU MHz:                         2199.998\n",
            "BogoMIPS:                        4399.99\n",
            "Hypervisor vendor:               KVM\n",
            "Virtualization type:             full\n",
            "L1d cache:                       32 KiB\n",
            "L1i cache:                       32 KiB\n",
            "L2 cache:                        256 KiB\n",
            "L3 cache:                        55 MiB\n",
            "NUMA node0 CPU(s):               0,1\n",
            "Vulnerability Itlb multihit:     Not affected\n",
            "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
            "Vulnerability Mds:               Vulnerable; SMT Host state unknown\n",
            "Vulnerability Meltdown:          Vulnerable\n",
            "Vulnerability Mmio stale data:   Vulnerable\n",
            "Vulnerability Retbleed:          Vulnerable\n",
            "Vulnerability Spec store bypass: Vulnerable\n",
            "Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and use\n",
            "                                 rcopy barriers only; no swapgs barriers\n",
            "Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PB\n",
            "                                 RSB-eIBRS: Not affected\n",
            "Vulnerability Srbds:             Not affected\n",
            "Vulnerability Tsx async abort:   Vulnerable\n",
            "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
            "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
            "                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant\n",
            "                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid \n",
            "                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci\n",
            "                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a\n",
            "                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref\n",
            "                                 etch invpcid_single ssbd ibrs ibpb stibp fsgsba\n",
            "                                 se tsc_adjust bmi1 hle avx2 smep bmi2 erms invp\n",
            "                                 cid rtm rdseed adx smap xsaveopt arat md_clear \n",
            "                                 arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dependencies"
      ],
      "metadata": {
        "id": "_pjxkzC_1eoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o3lARpKJxGvz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "import struct\n",
        "import random\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "We use a MNIST dataset distribution from keras here."
      ],
      "metadata": {
        "id": "8UFPPK46Fsaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
        "print (\"MNIST data loaded\")\n",
        "print (\"Training data shape:\",train_data.shape)\n",
        "print (\"Test data shape:\",test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd-LWa2DxK60",
        "outputId": "41389e65-8b75-4aeb-a82e-25b45a1ccdf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST data loaded\n",
            "Training data shape: (60000, 28, 28)\n",
            "Test data shape: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the dataset with the mean value and standard deviation of the training set."
      ],
      "metadata": {
        "id": "IOiy_yb7P_KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(train_data)\n",
        "std = np.std(train_data)\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "test_data = (test_data - mean) / std"
      ],
      "metadata": {
        "id": "bo86LKYRPuaz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code up net layers\n",
        "\n",
        "Here's the implementation of network layers.\n",
        "\n",
        "Please note that all tensors are of (N, C, H, W) manner."
      ],
      "metadata": {
        "id": "zpyap_sz1WsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv():\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, padding=0, bias=True):\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.kernel_size = kernel_size\n",
        "        self.weight = {'val': np.random.normal(0.0,np.sqrt(2/in_ch),(out_ch,in_ch,kernel_size,kernel_size)), 'grad': 0} # Xavier Initialization\n",
        "        self.b = {'val': np.random.randn(out_ch), 'grad': 0}\n",
        "        self.cache = None\n",
        "        self.pad = padding\n",
        "\n",
        "    def _forward(self, X):\n",
        "        X = np.pad(X, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), 'constant')\n",
        "        (N, in_ch, H, W) = X.shape\n",
        "        H_ = H - self.kernel_size + 1\n",
        "        W_ = W - self.kernel_size + 1\n",
        "        Y = np.zeros((N, self.out_ch, H_, W_))\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(self.out_ch):\n",
        "                for h in range(H_):\n",
        "                    for w in range(W_):\n",
        "                        Y[n, c, h, w] = np.sum(X[n, :, h:h+self.kernel_size, w:w+self.kernel_size] * self.weight['val'][c, :, :, :]) + self.b['val'][c]\n",
        "\n",
        "        self.cache = X\n",
        "        return Y\n",
        "\n",
        "    def _backward(self, dout):\n",
        "        X = self.cache\n",
        "        (N, in_ch, H, W) = X.shape\n",
        "        H_ = H - self.kernel_size + 1\n",
        "        W_ = W - self.kernel_size + 1\n",
        "        W_rot = np.rot90(np.rot90(self.weight['val']))\n",
        "\n",
        "        dX = np.zeros(X.shape)\n",
        "        dW = np.zeros(self.weight['val'].shape)\n",
        "        db = np.zeros(self.b['val'].shape)\n",
        "\n",
        "        for co in range(self.out_ch):\n",
        "            for ci in range(self.in_ch):\n",
        "                for h in range(self.kernel_size):\n",
        "                    for w in range(self.kernel_size):\n",
        "                        dW[co, ci, h, w] = np.sum(X[:,ci,h:h+H_,w:w+W_] * dout[:,co,:,:])\n",
        "\n",
        "        for co in range(self.out_ch):\n",
        "            db[co] = np.sum(dout[:,co,:,:])\n",
        "        dout_pad = np.pad(dout, ((0,0),(0,0),(self.kernel_size,self.kernel_size),(self.kernel_size,self.kernel_size)), 'constant')\n",
        "\n",
        "\n",
        "        for n in range(N):\n",
        "            for ci in range(self.in_ch):\n",
        "                for h in range(H):\n",
        "                    for w in range(W):\n",
        "                        dX[n, ci, h, w] = np.sum(W_rot[:,ci,:,:] * dout_pad[n, :, h:h+self.kernel_size,w:w+self.kernel_size])\n",
        "\n",
        "        self.weight['grad'] = dW\n",
        "        self.b['grad'] = db\n",
        "\n",
        "        return dX"
      ],
      "metadata": {
        "id": "qHHh642l1czX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool():\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.cache = None\n",
        "\n",
        "    def _forward(self, X):\n",
        "        (N,in_ch,H,W) = X.shape\n",
        "        kernel_size = self.kernel_size\n",
        "        W_ = int(float(W)/kernel_size)\n",
        "        H_ = int(float(H)/kernel_size)\n",
        "        Y = np.zeros((N,in_ch,W_,H_))\n",
        "        M = np.zeros(X.shape) \n",
        "        for n in range(N):\n",
        "            for cin in range(in_ch):\n",
        "                for w_ in range(W_):\n",
        "                    for h_ in range(H_):\n",
        "                        Y[n,cin,w_,h_] = np.max(X[n,cin,kernel_size*w_:kernel_size*(w_+1),kernel_size*h_:kernel_size*(h_+1)])\n",
        "                        i,j = np.unravel_index(X[n,cin,kernel_size*w_:kernel_size*(w_+1),kernel_size*h_:kernel_size*(h_+1)].argmax(), (kernel_size,kernel_size))\n",
        "                        M[n,cin,kernel_size*w_+i,kernel_size*h_+j] = 1\n",
        "        self.cache = M\n",
        "        return Y\n",
        "\n",
        "    def _backward(self, dout):\n",
        "        M = self.cache\n",
        "        (N,in_ch,H,W) = M.shape\n",
        "        dout = np.array(dout)\n",
        "        dX = np.zeros(M.shape)\n",
        "        for n in range(N):\n",
        "            for c in range(in_ch):\n",
        "                dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
        "        return dX*M"
      ],
      "metadata": {
        "id": "Vz1M9Kh-2DAp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU():\n",
        "    def __init__(self):\n",
        "        self.cache = None\n",
        "\n",
        "    def _forward(self, X):\n",
        "        out = np.maximum(0, X)\n",
        "        self.cache = X\n",
        "        return out\n",
        "\n",
        "    def _backward(self, dout):\n",
        "        X = self.cache\n",
        "        dX = np.array(dout, copy=True)\n",
        "        dX[X <= 0] = 0\n",
        "        return dX"
      ],
      "metadata": {
        "id": "mutCvKCZ2Nmv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC():\n",
        "    def __init__(self, D_in, D_out):\n",
        "        self.cache = None\n",
        "        self.weight = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
        "        self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
        "\n",
        "    def _forward(self, X):\n",
        "        out = np.dot(X, self.weight['val']) + self.b['val']\n",
        "        self.cache = X\n",
        "        return out\n",
        "\n",
        "    def _backward(self, dout):\n",
        "        X = self.cache\n",
        "        dX = np.dot(dout, self.weight['val'].T).reshape(X.shape)\n",
        "        self.weight['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
        "        self.b['grad'] = np.sum(dout, axis=0)\n",
        "        return dX"
      ],
      "metadata": {
        "id": "yiOJ9tMj2UaT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizer and loss function\n",
        "This is an implementation of stochastic gradient descent optimizer."
      ],
      "metadata": {
        "id": "Nhsc4zrPQaEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD():\n",
        "    def __init__(self, params, lr=0.001, weight_decay=0):\n",
        "        self.parameters = params\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def step(self):\n",
        "        for param in self.parameters:\n",
        "            param['val'] -= (self.lr*param['grad'] + self.weight_decay*param['val'])\n"
      ],
      "metadata": {
        "id": "wLaMKPPA2c5l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an implementation of Cross entropy loss."
      ],
      "metadata": {
        "id": "5Ab9IJDG_QjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax():\n",
        "    def __init__(self):\n",
        "        self.cache = None\n",
        "\n",
        "    def _forward(self, X):\n",
        "        maxes = np.amax(X, axis=1)\n",
        "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
        "        Y = np.exp(X - maxes)\n",
        "        Z = Y / np.sum(Y, axis=1).reshape(Y.shape[0], 1)\n",
        "        self.cache = (X, Y, Z)\n",
        "        return Z\n",
        "\n",
        "    def _backward(self, dout):\n",
        "        X, Y, Z = self.cache\n",
        "        dZ = np.zeros(X.shape)\n",
        "        dY = np.zeros(X.shape)\n",
        "        dX = np.zeros(X.shape)\n",
        "        N = X.shape[0]\n",
        "        for n in range(N):\n",
        "            i = np.argmax(Z[n])\n",
        "            dZ[n,:] = np.diag(Z[n]) - np.outer(Z[n],Z[n])\n",
        "            M = np.zeros((N,N))\n",
        "            M[:,i] = 1\n",
        "            dY[n,:] = np.eye(N) - M\n",
        "        dX = np.dot(dout,dZ)\n",
        "        dX = np.dot(dX,dY)\n",
        "        return dX"
      ],
      "metadata": {
        "id": "v5VP3ogX3PX-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NLLLoss(Y_pred, Y_true):\n",
        "    loss = 0.0\n",
        "    N = Y_pred.shape[0]\n",
        "    M = np.sum(Y_pred*Y_true, axis=1)\n",
        "    for e in M:\n",
        "        #print(e)\n",
        "        if e == 0:\n",
        "            loss += 500\n",
        "        else:\n",
        "            loss += -np.log(e)\n",
        "    return loss/N"
      ],
      "metadata": {
        "id": "AW5OYYo93TBQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropyLoss():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get(self, Y_pred, Y_true):\n",
        "        N = Y_pred.shape[0]\n",
        "        softmax = Softmax()\n",
        "        prob = softmax._forward(Y_pred)\n",
        "        loss = NLLLoss(prob, Y_true)\n",
        "        Y_serial = np.argmax(Y_true, axis=1)\n",
        "        dout = prob.copy()\n",
        "        dout[np.arange(N), Y_serial] -= 1\n",
        "        return loss, dout"
      ],
      "metadata": {
        "id": "7c-KXp-63Hlg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions."
      ],
      "metadata": {
        "id": "cbLm3Ts0_dZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MakeOneHot(Y, D_out):\n",
        "    N = Y.shape[0]\n",
        "    Z = np.zeros((N, D_out))\n",
        "    Z[np.arange(N), Y] = 1\n",
        "    return Z"
      ],
      "metadata": {
        "id": "GgUPG9HV36At"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter():\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "kMFFq4Jfaf7L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an easy implementation of dataset:"
      ],
      "metadata": {
        "id": "ALXUvIPTeiQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset():\n",
        "  def __init__(self, data, label, batch_size) -> None:\n",
        "    self.data = np.expand_dims(data, axis=1)\n",
        "    self.label = label\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if index >= len(self):\n",
        "      raise IndexError\n",
        "    lower = index * self.batch_size\n",
        "    higher = min(lower + self.batch_size, self.data.shape[0])\n",
        "    x = np.zeros((self.batch_size, 1, self.data.shape[1], self.data.shape[2]))\n",
        "    y = np.array(self.label[lower:higher])\n",
        "    x = self.data[lower:higher,:]\n",
        "    y = MakeOneHot(y, 10)\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return np.ceil(self.data.shape[0]/self.batch_size).astype(int)"
      ],
      "metadata": {
        "id": "s7WGyFqDUD0-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code up LeNet-5"
      ],
      "metadata": {
        "id": "51UR3KaW1qou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5():\n",
        "    # Credit to Lecun Yann\n",
        "    def __init__(self):\n",
        "        self.conv1 = Conv(1, 6, 5)\n",
        "        self.ReLU1 = ReLU()\n",
        "        self.pool1 = MaxPool(2)\n",
        "        self.conv2 = Conv(6, 16, 5)\n",
        "        self.ReLU2 = ReLU()\n",
        "        self.pool2 = MaxPool(2)\n",
        "        self.FC1 = FC(16*4*4, 120)\n",
        "        self.ReLU3 = ReLU()\n",
        "        self.FC2 = FC(120, 84)\n",
        "        self.ReLU4 = ReLU()\n",
        "        self.FC3 = FC(84, 10)\n",
        "        self.p2_shape = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        h1 = self.conv1._forward(X)\n",
        "        a1 = self.ReLU1._forward(h1)\n",
        "        p1 = self.pool1._forward(a1)\n",
        "        h2 = self.conv2._forward(p1)\n",
        "        a2 = self.ReLU2._forward(h2)\n",
        "        p2 = self.pool2._forward(a2)\n",
        "        self.p2_shape = p2.shape\n",
        "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
        "        h3 = self.FC1._forward(fl)\n",
        "        a3 = self.ReLU3._forward(h3)\n",
        "        h4 = self.FC2._forward(a3)\n",
        "        a5 = self.ReLU4._forward(h4)\n",
        "        h5 = self.FC3._forward(a5)\n",
        "        return h5\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = self.FC3._backward(dout)\n",
        "        dout = self.ReLU4._backward(dout)\n",
        "        dout = self.FC2._backward(dout)\n",
        "        dout = self.ReLU3._backward(dout)\n",
        "        dout = self.FC1._backward(dout)\n",
        "        dout = dout.reshape(self.p2_shape) # reshape\n",
        "        dout = self.pool2._backward(dout)\n",
        "        dout = self.ReLU2._backward(dout)\n",
        "        dout = self.conv2._backward(dout)\n",
        "        dout = self.pool1._backward(dout)\n",
        "        dout = self.ReLU1._backward(dout)\n",
        "        dout = self.conv1._backward(dout)\n",
        "\n",
        "    def get_params(self):\n",
        "        return [self.conv1.weight, self.conv1.b, self.conv2.weight, self.conv2.b, self.FC1.weight, self.FC1.b, self.FC2.weight, self.FC2.b, self.FC3.weight, self.FC3.b]\n",
        "\n",
        "    def set_params(self, params):\n",
        "        [self.conv1.weight, self.conv1.b, self.conv2.weight, self.conv2.b, self.FC1.weight, self.FC1.b, self.FC2.weight, self.FC2.b, self.FC3.weight, self.FC3.b] = params\n"
      ],
      "metadata": {
        "id": "CbOj46G4DdLU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training\n",
        "Hyperparams go here:"
      ],
      "metadata": {
        "id": "uC2hlOo7RGhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "LR = 0.0001\n",
        "WEIGHT_DECAY = 0.0003\n",
        "EPOCHES = 2"
      ],
      "metadata": {
        "id": "ExAG8TL0RJQ5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = dataset(train_data, train_label, BATCH_SIZE)\n",
        "test_loader = dataset(test_data, test_label, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "W3uwhaARWT-q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet5()\n",
        "losses = AverageMeter()\n",
        "optim = SGD(model.get_params(), lr=LR, weight_decay=WEIGHT_DECAY) \n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(EPOCHES):\n",
        "  print(f\"Epoch {epoch}:\\n\")\n",
        "  pbar = tqdm.tqdm(range(len(train_loader))) \n",
        "  for i, (x, y) in enumerate(train_loader):\n",
        "    logit = model.forward(x)\n",
        "    loss, dout = criterion.get(logit, y)\n",
        "    model.backward(dout)\n",
        "    optim.step()\n",
        "\n",
        "    losses.update(loss)\n",
        "    pbar.update()\n",
        "    pbar.set_description(\"loss:{}\".format(losses.avg))\n",
        "  pbar.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbFnNwaR2leb",
        "outputId": "612fb1ce-1a69-4aa6-dc7b-94332b441e16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss:1.0249430018772885: 100%|██████████| 1875/1875 [1:19:28<00:00,  2.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss:0.6611204721031742: 100%|██████████| 1875/1875 [1:19:58<00:00,  2.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test result"
      ],
      "metadata": {
        "id": "izbPfWvI9iXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = np.zeros((10,10),int)\n",
        "for i,(x, y) in enumerate(test_loader):\n",
        "  logit = model.forward(x)\n",
        "  pred = np.argmax(logit, axis=1)\n",
        "  gt = np.argmax(y, axis=1)\n",
        "  for j in range(len(pred)):\n",
        "    confusion_matrix[gt[j]][pred[j]] += 1\n",
        "\n",
        "acc = confusion_matrix.diagonal().sum() / confusion_matrix.sum()\n",
        "print(\"Test accuracy is: {}\".format(acc))\n",
        "print(\"Confusion matrix:\\n\",confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MA1xCKcr9n",
        "outputId": "5a52bf41-a136-4da2-98c3-25a4f459963a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: 0.9301\n",
            "Confusion matrix:\n",
            " [[ 965    2    1    0    0    2    4    1    4    1]\n",
            " [   0 1120    1    4    0    0    4    0    5    1]\n",
            " [  12    3  937   12   19    0    7   14   19    9]\n",
            " [   7    0   12  942    1   22    2    8    9    7]\n",
            " [   2    7    4    0  888    0    8    0    4   69]\n",
            " [  13    1    3   32    3  815    5    2   10    8]\n",
            " [  17    6    7    2    9   24  888    0    5    0]\n",
            " [   4   17   35    3    8    2    0  911    5   43]\n",
            " [   5    4    2   22    6   17    4    7  885   22]\n",
            " [  12    6    5   12    7    6    0    5    6  950]]\n"
          ]
        }
      ]
    }
  ]
}